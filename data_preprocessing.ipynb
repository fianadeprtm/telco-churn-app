{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b229a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data_processing.py...\n",
      "ðŸ“¥ Memuat dataset...\n",
      "âœ… Dataset dimuat: 7043 baris, 21 kolom\n",
      "ðŸ”„ Imputed missing values in TotalCharges\n",
      "ðŸ”§ Membuat preprocessor:\n",
      "   - Kolom numerik: ['SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges']\n",
      "   - Kolom kategorikal: ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']\n",
      "ðŸ“Š Data split:\n",
      "   X_train: (5634, 30)\n",
      "   X_test: (1409, 30)\n",
      "   y_train: (5634,)\n",
      "   y_test: (1409,)\n",
      "ðŸ’¾ Preprocessor disimpan sebagai: preprocessor.pkl\n"
     ]
    }
   ],
   "source": [
    "# data_processing.py\n",
    "\"\"\"\n",
    "Script untuk preprocessing data churn prediction\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import joblib\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Load dataset dari URL\n",
    "    \"\"\"\n",
    "    print(\"ðŸ“¥ Memuat dataset...\")\n",
    "    url = \"https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv\"\n",
    "    df = pd.read_csv(url)\n",
    "    print(f\"âœ… Dataset dimuat: {df.shape[0]} baris, {df.shape[1]} kolom\")\n",
    "    return df\n",
    "\n",
    "def clean_data(df):\n",
    "    \"\"\"\n",
    "    Membersihkan data\n",
    "    \"\"\"\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Konversi TotalCharges ke numeric\n",
    "    df_clean['TotalCharges'] = pd.to_numeric(df_clean['TotalCharges'], errors='coerce')\n",
    "    \n",
    "    # Handle missing values\n",
    "    if df_clean['TotalCharges'].isnull().sum() > 0:\n",
    "        df_clean['TotalCharges'] = df_clean['TotalCharges'].fillna(df_clean['TotalCharges'].median())\n",
    "        print(f\"ðŸ”„ Imputed missing values in TotalCharges\")\n",
    "    \n",
    "    # Encode target variable\n",
    "    df_clean['Churn'] = df_clean['Churn'].map({'No': 0, 'Yes': 1})\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "def create_preprocessor(X):\n",
    "    \"\"\"\n",
    "    Membuat preprocessor pipeline\n",
    "    \"\"\"\n",
    "    # Identifikasi kolom\n",
    "    categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "    numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    \n",
    "    print(f\"ðŸ”§ Membuat preprocessor:\")\n",
    "    print(f\"   - Kolom numerik: {numeric_cols}\")\n",
    "    print(f\"   - Kolom kategorikal: {categorical_cols}\")\n",
    "    \n",
    "    # Buat preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numeric_cols),\n",
    "            ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_cols)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return preprocessor\n",
    "\n",
    "def prepare_training_data(df):\n",
    "    \"\"\"\n",
    "    Menyiapkan data untuk training\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    # Pisahkan features dan target\n",
    "    X = df.drop(['customerID', 'Churn'], axis=1)\n",
    "    y = df['Churn']\n",
    "    \n",
    "    # Buat preprocessor\n",
    "    preprocessor = create_preprocessor(X)\n",
    "    \n",
    "    # Transform data\n",
    "    X_transformed = preprocessor.fit_transform(X)\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_transformed, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"ðŸ“Š Data split:\")\n",
    "    print(f\"   X_train: {X_train.shape}\")\n",
    "    print(f\"   X_test: {X_test.shape}\")\n",
    "    print(f\"   y_train: {y_train.shape}\")\n",
    "    print(f\"   y_test: {y_test.shape}\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, preprocessor\n",
    "\n",
    "def save_preprocessor(preprocessor, filename='preprocessor.pkl'):\n",
    "    \"\"\"\n",
    "    Simpan preprocessor ke file\n",
    "    \"\"\"\n",
    "    joblib.dump(preprocessor, filename)\n",
    "    print(f\"ðŸ’¾ Preprocessor disimpan sebagai: {filename}\")\n",
    "\n",
    "def load_preprocessor(filename='preprocessor.pkl'):\n",
    "    \"\"\"\n",
    "    Load preprocessor dari file\n",
    "    \"\"\"\n",
    "    return joblib.load(filename)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Contoh penggunaan\n",
    "    print(\"Testing data_processing.py...\")\n",
    "    df = load_data()\n",
    "    df_clean = clean_data(df)\n",
    "    X_train, X_test, y_train, y_test, preprocessor = prepare_training_data(df_clean)\n",
    "    save_preprocessor(preprocessor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
